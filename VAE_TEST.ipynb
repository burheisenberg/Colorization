{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataset_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-841147f62df1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# custom dataset class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dataset_loader'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# custom dataset class\n",
    "from dataset_loader import CustomDataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, latent_size):\n",
    "        super(ConvVAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1), # output 150x150 -> 150x150\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=2), # output 150x150 -> 152x152\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 152 -> 76\n",
    "        )\n",
    "        \n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=2), # output 76x76 -> 78x78\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 78 -> 39\n",
    "        )\n",
    "        \n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=2), # output 39x39 -> 41x41\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 41 -> 20\n",
    "        )\n",
    "        \n",
    "        self.encoder5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=2), # output 20x20 -> 22x22\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 22 -> 11\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1), # same: 11 -> 11\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1), # same: 11 -> 11\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.Upsample(size=(20,20),mode='nearest'), # output 11x11 -> 20x20\n",
    "            nn.Conv2d(512,256, kernel_size=3, stride=1, padding=1), # same 20 -> 20\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.LeakyReLU(negative_slope=0.01,inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.Upsample(size=(39,39),mode='nearest'), # output 20x20 -> 39x39\n",
    "            nn.Conv2d(512,128, kernel_size=3, stride=1, padding=1), # same 39 -> 39\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.LeakyReLU(negative_slope=0.01,inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.Upsample(size=(76,76),mode='nearest'), # output 39x39 -> 76x76\n",
    "            nn.Conv2d(256,64, kernel_size=3, stride=1, padding=1), # same 76 -> 76\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.LeakyReLU(negative_slope=0.01,inplace=True)\n",
    "        )\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.Upsample(size=(150,150),mode='nearest'), # output 76x76 -> 150x150\n",
    "            nn.Conv2d(128,32, kernel_size=3, stride=1, padding=1), # same 150 -> 150\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.LeakyReLU(negative_slope=0.01,inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), # same: 150 -> 150\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), # same: 150 -> 150\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), # same: 150 -> 150\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, out_channels, kernel_size=3, stride=1, padding=1), # same: 150 -> 150\n",
    "        )\n",
    "        \n",
    "        ### Fully connected layers for mean and logvar ###\n",
    "        self.mean = nn.Sequential(\n",
    "            nn.Linear(512*11*11, latent_size),\n",
    "            nn.BatchNorm1d(latent_size),  # Batch Normalization\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(latent_size, 512 * 11 * 11),\n",
    "            nn.BatchNorm1d(512 * 11 * 11),  # Batch Normalization\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Unflatten(1, (512, 11, 11))  # Reshape to match the shape after encoder\n",
    "        )\n",
    "        self.logvar = nn.Sequential(\n",
    "            nn.Linear(512*11*11, latent_size),\n",
    "            nn.BatchNorm1d(latent_size),  # Batch Normalization\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(latent_size, 512*11*11),\n",
    "            nn.BatchNorm1d(512*11*11),  # Batch Normalization\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Unflatten(1, (512, 11, 11))  # Reshape to match the shape after encoder\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def encode(self, x):\n",
    "        x1 = self.encoder1(x)\n",
    "        x2 = self.encoder2(x1)\n",
    "        x3 = self.encoder3(x2)\n",
    "        x4 = self.encoder4(x3)\n",
    "        x5 = self.encoder5(x4)\n",
    "        return x1, x2, x3, x4, x5\n",
    "\n",
    "    def decode(self, x1, x2, x3, x4, x5):\n",
    "        z = self.decoder1(x5)\n",
    "        z = self.decoder2(torch.cat((z,x4), dim=1))\n",
    "        z = self.decoder3(torch.cat((z,x3), dim=1))\n",
    "        z = self.decoder4(torch.cat((z,x2), dim=1))\n",
    "        z = self.decoder5(torch.cat((z,x1), dim=1))\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2, x3, x4, x5 = self.encode(x)\n",
    "        \n",
    "        mean = self.mean(x5.reshape(x5.shape[0],-1))\n",
    "        logvar = self.logvar(x5.reshape(x5.shape[0],-1))\n",
    "        x5 = self.reparameterize(mean,logvar)\n",
    "        \n",
    "        x_recon = self.decode(x1, x2, x3, x4, x5)\n",
    "        return x_recon, mean, logvar\n",
    "\n",
    "# Define the loss function for Convolutional VAE\n",
    "def conv_vae_loss(recon_x, x, mu, logvar):\n",
    "    #BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    MSE = F.mse_loss(recon_x, x, reduction='mean')\n",
    "    \n",
    "    # KL divergence\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return MSE + KLD\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_vae(model, train_loader, optimizer, num_epochs=5):\n",
    "    # Training loop\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "    # Lists to store loss values for plotting\n",
    "    all_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        epoch_losses = []\n",
    "\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = conv_vae(inputs)\n",
    "            loss = conv_vae_loss(recon_batch, targets, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "            if batch_idx % 100 == 99:\n",
    "                print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(inputs), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    loss.item() / len(inputs)))\n",
    "\n",
    "        # Save average loss for the epoch\n",
    "        avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "        all_losses.append(avg_epoch_loss)\n",
    "\n",
    "        # decrease the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "    # Plot the loss over epochs\n",
    "    plt.plot(range(1, num_epochs + 1), all_losses, marker='o')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set your dataset path and other parameters\n",
    "input_folder = \"landscape_images\\gray\"\n",
    "output_folder = \"landscape_images\\color\"\n",
    "batch_size = 4\n",
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "latent_size = 20\n",
    "\n",
    "\n",
    "# Transformations for output images (no grayscale conversion)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load your dataset with separate transforms for input and output\n",
    "dataset = CustomDataset(input_folder, output_folder, transform=transform)\n",
    "\n",
    "# Split it into train and test data\n",
    "train_size = 32 #int(0.001 * len(dataset))  # Adjust the split ratio as needed\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create the dataloader using only the transform for input images\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# Instantiate the Convolutional VAE model and optimizer\n",
    "conv_vae = ConvVAE(in_channels=1, out_channels=3,latent_size=latent_size).to(device)\n",
    "optimizer = optim.Adam(conv_vae.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "train=0\n",
    "\n",
    "if train:\n",
    "    train_vae(conv_vae, train_loader, optimizer, epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model weights\n",
    "save_params= 0\n",
    "if save_params:\n",
    "    torch.save(conv_vae.state_dict(), \"generative_models/004_params/004_vae_weights_g2c.pth\")\n",
    "    torch.save(conv_vae, \"generative_models/004_params/004_vae_g2c.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "conv_vae = ConvVAE(in_channels=1, out_channels=3,latent_size=latent_size).to(device)\n",
    "conv_vae.load_state_dict(torch.load(\"generative_models/005_params/005_vae_weights_g2c.pth\"))\n",
    "conv_vae.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Create a test data loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define a loss function (e.g., mean squared error for regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Evaluate on the test set\n",
    "test = 0\n",
    "if test:\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs,_,_ = conv_vae(inputs.to(device))\n",
    "            outputs = outputs.detach().cpu()\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * targets.size(0)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(\"Test Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate a sample from the Convolutional VAE, this part can be used for both image generation and noise testing\n",
    "with torch.no_grad():\n",
    "    sample = torch.randn([32, 3, 150, 150]).to(device)\n",
    "    #sample = conv_vae.forward(sample)\n",
    "    \n",
    "    # Get a test image and target\n",
    "    input_images, target_images = next(iter(train_loader)) # .to(device) #+sample*0.5\n",
    "    input_images, target_images = input_images.to(device), target_images.to(device)\n",
    "    output_images,_,_ = conv_vae(input_images)\n",
    "\n",
    "\n",
    "# You can then visualize the generated samples using a library like matplotlib\n",
    "fig, axes = plt.subplots(batch_size, 2, figsize=(20,10))\n",
    "\n",
    "for i in range(batch_size):\n",
    "\n",
    "    # Get the current target image\n",
    "    output_image = output_images[i,:,:,:].squeeze().detach().cpu()\n",
    "\n",
    "    # target_image is already a numpy array, just squeeze it:\n",
    "    target_image = target_images[i,:,:,:].squeeze().detach().cpu()\n",
    "\n",
    "    # Normalize predictions and targets to [0, 1]\n",
    "    target_image = (target_image - target_image.min()) / (target_image.max() - target_image.min())\n",
    "    output_image = (output_image - output_image.min()) / (output_image.max() - output_image.min())\n",
    "\n",
    "\n",
    "    # torch tensor has permute\n",
    "    axes[i,0].imshow(target_image.permute(1,2,0))\n",
    "    axes[i,0].set_title(\"Target Image\")\n",
    "    # torch tensor has permute\n",
    "    axes[i,1].imshow(output_image.permute(1,2,0))\n",
    "    axes[i,1].set_title(\"Output Image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.Tensor(sample).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss /= len(train_loader.dataset)\n",
    "print(\"Test Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
